{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hCJ0aSOo4zBQ"
      },
      "outputs": [],
      "source": [
        "# Import Module\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data train\n",
        "data_train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Replace String \"USER\" in Text Column \n",
        "data_train[\"text\"] = data_train[\"text\"].apply(lambda x: x.replace(\"USER\", \"\"))\n",
        "\n",
        "# Load data test\n",
        "data_test = pd.read_csv(\"test.csv\")\n",
        "print(data_test)\n",
        "# Replace String \"USER\" in Text Column \n",
        "data_test[\"text\"] = data_test[\"text\"].apply(lambda x: x.replace(\"USER\", \"\"))\n",
        "\n",
        "# Delete Hexadecimal in Text Column\n",
        "import re\n",
        "def remove_hexadecimals(text):\n",
        "    return re.sub(r'\\\\x[\\da-fA-F]+', '', text)\n",
        "data_test['text'] = data_test['text'].apply(remove_hexadecimals)\n",
        "data_train['text'] = data_train['text'].apply(remove_hexadecimals)\n",
        "\n",
        "teks = data_train['text'].astype(str) # Input\n",
        "y = data_train['label'].astype(int) # Target Model\n",
        "teks_test = data_test['text'].astype(str) # Predict Input\n",
        "ID = data_test['id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UutY297s5OGA",
        "outputId": "cde95db1-3ea8-4838-c8a7-cd1d40e3fe99"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id                                               text\n",
            "0     11371                 USER USER Nanti orang Hindu marah'\n",
            "1     12140  USER Pak USER saya ttap mendesak Anda menyatak...\n",
            "2     11170   BERSIKAP KERASLAH TERHADAP MEREKA?CINA KAFIR URL\n",
            "3      1265  USER Ganti casing aja ,padahal nyatanya akusis...\n",
            "4     12098  USER mataku ku sipit sipitin dikit. sekelibet ...\n",
            "...     ...                                                ...\n",
            "2629   7390  USER USER USER USER USER USER USER eh dongo, k...\n",
            "2630   3019  USER USER Kalau saya melihat kok yang kebanget...\n",
            "2631  13145  USER Goblok, bayangin aja kalo janin itu lu (y...\n",
            "2632   4603  RT USER USER USER Klop pemberontak sekaligus k...\n",
            "2633   6116  USER USER Cebong juara satu lari dari kenyataa...\n",
            "\n",
            "[2634 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(teks)\n",
        "sequences = tokenizer.texts_to_sequences(teks)\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_len = max([len(s.split()) for s in teks])\n",
        "x = pad_sequences(sequences, maxlen=max_len)"
      ],
      "metadata": {
        "id": "TP6h-soN5Q94"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=10, batch_size=32, validation_split=0.5)\n",
        "\n",
        "sequences_test = tokenizer.texts_to_sequences(teks_test)\n",
        "x_test = pad_sequences(sequences_test, maxlen=max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtcSKdwN5S8L",
        "outputId": "b6d72f13-91d0-4805-d06f-809fb588fab9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 0.3050 - accuracy: 0.9102 - val_loss: 0.2954 - val_accuracy: 0.9081\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 8s 46ms/step - loss: 0.2304 - accuracy: 0.9149 - val_loss: 0.2801 - val_accuracy: 0.9081\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 8s 51ms/step - loss: 0.1254 - accuracy: 0.9468 - val_loss: 0.4113 - val_accuracy: 0.9148\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 7s 45ms/step - loss: 0.0612 - accuracy: 0.9772 - val_loss: 0.4675 - val_accuracy: 0.9049\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 8s 51ms/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 0.5505 - val_accuracy: 0.9081\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 8s 50ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.6097 - val_accuracy: 0.9036\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 8s 49ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.6283 - val_accuracy: 0.8948\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 10s 62ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.6394 - val_accuracy: 0.8956\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 10s 59ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 0.6736 - val_accuracy: 0.9009\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 10s 59ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.6836 - val_accuracy: 0.8920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi\n",
        "predictions = model.predict(x_test)\n",
        "predictions = np.round(predictions).astype(int)\n",
        "prediction_percentage = sum(predictions == [0, 1]) / len(predictions) * 100\n",
        "print(\"Prediksi : \", prediction_percentage)\n",
        "prediction_percentage = len(predictions) / len(x_test)\n",
        "\n",
        "data_test['label'] = predictions\n",
        "print(data_test[['id','text','label']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcKmGvso5UUp",
        "outputId": "8284daad-5efd-4377-9670-227710efdfe0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 0s 4ms/step\n",
            "Prediksi :  [93.47000759  6.52999241]\n",
            "         id                                               text  label\n",
            "0     11371                           Nanti orang Hindu marah'      0\n",
            "1     12140   Pak  saya ttap mendesak Anda menyatakan Muham...      0\n",
            "2     11170   BERSIKAP KERASLAH TERHADAP MEREKA?CINA KAFIR URL      0\n",
            "3      1265   Ganti casing aja ,padahal nyatanya akusisi it...      0\n",
            "4     12098    mataku ku sipit sipitin dikit. sekelibet mirip'      0\n",
            "...     ...                                                ...    ...\n",
            "2629   7390         eh dongo, klo namannya di tackle terus ...      0\n",
            "2630   3019    Kalau saya melihat kok yang kebangeten itu p...      0\n",
            "2631  13145   Goblok, bayangin aja kalo janin itu lu (yg ng...      0\n",
            "2632   4603         RT    Klop pemberontak sekaligus koruptor.      0\n",
            "2633   6116    Cebong juara satu lari dari kenyataan,kepint...      0\n",
            "\n",
            "[2634 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test.to_excel('result.xlsx', index=False)"
      ],
      "metadata": {
        "id": "ZwgJmh1a5V8H"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}